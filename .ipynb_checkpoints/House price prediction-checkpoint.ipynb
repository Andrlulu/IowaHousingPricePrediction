{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Show all columns, rows, width\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & Inspect data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv', index_col = 0)\n",
    "test_df = pd.read_csv('./data/test.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function impute_missing takes dataframe which needs to be imputed as input variable\n",
    "def impute_missing(dfName):\n",
    "    \n",
    " # impute GarageYrBlt with min GarageYrBlt for houses with no garage    \n",
    "    dfName['GarageYrBlt'] = dfName['GarageYrBlt'].fillna(min(dfName['GarageYrBlt']))\n",
    "    \n",
    " # impute MasVnrArea to 0 because for NAs we are imputing type to None   \n",
    "    dfName['MasVnrArea'] = dfName['MasVnrArea'].fillna(0)\n",
    "    dfName['BsmtFinSF1'] = dfName['BsmtFinSF1'].fillna(0)\n",
    "    dfName['BsmtFinSF2'] = dfName['BsmtFinSF2'].fillna(0)\n",
    "    dfName['BsmtUnfSF'] = dfName['BsmtUnfSF'].fillna(0)\n",
    "    dfName['TotalBsmtSF'] = dfName['TotalBsmtSF'].fillna(0)\n",
    "    dfName['BsmtFullBath'] = dfName['BsmtFullBath'].fillna(0)\n",
    "    dfName['BsmtHalfBath'] = dfName['BsmtHalfBath'].fillna(0)\n",
    "    dfName['GarageCars'] = dfName['GarageCars'].fillna(0)\n",
    "    dfName['GarageArea'] = dfName['GarageArea'].fillna(0)\n",
    "\n",
    " #impute missing values by the median LotFrontage of the neighborhood.\n",
    "    dfName['LotFrontage'] = dfName.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    " # for missing in Electrical variable, impute with type which occurs most frequently\n",
    "    dfName['Electrical'] = dfName['Electrical'].fillna(dfName['Electrical'].mode()[0]) \n",
    "    dfName['MSZoning'] = dfName['MSZoning'].fillna(dfName['MSZoning'].mode()[0]) \n",
    "    dfName['Utilities'] = dfName['Utilities'].fillna(dfName['Utilities'].mode()[0]) \n",
    "    dfName['Exterior1st'] = dfName['Exterior1st'].fillna(dfName['Exterior1st'].mode()[0]) \n",
    "    dfName['Exterior2nd'] = dfName['Exterior2nd'].fillna(dfName['Exterior2nd'].mode()[0]) \n",
    "    dfName['KitchenQual'] = dfName['KitchenQual'].fillna(dfName['KitchenQual'].mode()[0])\n",
    "    dfName['Functional'] = dfName['Functional'].fillna(dfName['Functional'].mode()[0])\n",
    "    dfName['KitchenQual'] = dfName['KitchenQual'].fillna(dfName['KitchenQual'].mode()[0])\n",
    "    dfName['SaleType'] = dfName['SaleType'].fillna(dfName['SaleType'].mode()[0])\n",
    "\n",
    " # Check col names ad imputes None, 0 , or aggregated value based on algorithm       \n",
    "    for col in ('PoolQC','MiscFeature','Alley','Fence','FireplaceQu','GarageType','GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2', 'MasVnrType'):\n",
    "        dfName[col] = dfName[col].fillna('None') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "impute_missing(train_df)\n",
    "impute_missing(test_df)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(train_df[(train_df.GrLivArea>4000) & (train_df.SalePrice<300000)].index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define function to detect outliers\n",
    "# def detect_outliers(df,n,cols):\n",
    "#     outliner_index = []\n",
    "#     #iterate columns\n",
    "#     for col in cols:\n",
    "#         Q1 = np.percentile(df[col], 25)\n",
    "#         Q3 = np.percentile(df[col], 75)\n",
    "#         IQR = Q3 - Q1\n",
    "#         #calculate outliers bound\n",
    "#         bound = 1.5 * IQR\n",
    "#         lower_bound = Q1 - bound\n",
    "#         upper_bound = Q3 + bound\n",
    "#         #get list of outliners\n",
    "#         index = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "#         outliner_index.extend(index)\n",
    "#     outliner_index = Counter(outliner_index)\n",
    "#     multiple_outliners = list(k for k,v in outliner_index.items() if v > n)\n",
    "#     return multiple_outliners\n",
    "\n",
    "# #filter out rows contain 8 outliers \n",
    "# outlier_index = detect_outliers(train_df, 8, num_features)\n",
    "# #drop outliers\n",
    "# train_df.drop(outlier_index, inplace=True)\n",
    "# print(train_df.shape)\n",
    "# print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combine = pd.concat([train_df, test_df])\n",
    "\n",
    "cat_features = combine.dtypes[combine.dtypes == 'object'].index\n",
    "num_features = combine.dtypes[combine.dtypes != 'object'].index\n",
    "cat_extra = ['MSSubClass', 'OverallCond', 'OverallQual']\n",
    "combine[cat_extra] = combine[cat_extra].astype('object')\n",
    "cat_features = combine.dtypes[combine.dtypes == 'object'].index\n",
    "num_features = combine.dtypes[combine.dtypes != 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_col = ['LotFrontage', 'LotArea',  'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "          'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "          'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "           'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "           'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "           'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
    "           'MoSold', 'GarageYrBlt', 'YrSold', 'YearBuilt','YearRemodAdd']\n",
    "\n",
    "cat_col = list(set(train_df.columns)-set(cont_col)-{'SalePrice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 334)\n",
      "(1458, 334)\n",
      "(1459, 333)\n"
     ]
    }
   ],
   "source": [
    "#define get dummy function for all dummy variables\n",
    "def get_dummy(df, cols):\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, dummy_na=False)\n",
    "        df = df.drop(col, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "combine_d = get_dummy(combine, cat_col)\n",
    "\n",
    "print(combine_d.shape)\n",
    "\n",
    "dtrain = combine_d[combine_d.SalePrice.notnull()]\n",
    "dtest = combine_d[combine_d.SalePrice.isnull()].drop(columns = 'SalePrice')\n",
    "\n",
    "print(dtrain.shape)\n",
    "print(dtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add categorical col for 0 value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 349)\n",
      "(1459, 348)\n"
     ]
    }
   ],
   "source": [
    "inputcols = ['2ndFlrSF','BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\\\n",
    "             'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\\\n",
    "            'LowQualFinSF', 'PoolArea', 'MasVnrArea', 'MiscVal']\n",
    "outputcols = ['has2ndflr', 'hasbsmt1', 'hasbsmt2', 'isbsmtcomplete', 'hasbsmt', 'hasgarage', 'haswooddeck', 'hasopenporch',\\\n",
    "             'hasenclosedporch', 'has3ssnporch', 'hasscreenporch', 'islowqualfin', 'haspool', 'hasmasvnr', 'hasmiscval']\n",
    "\n",
    "def add_categorical_col(df, inputcols, outputcols):\n",
    "    if len(inputcols) != len(outputcols):\n",
    "        raise \"Col len does not equal\"\n",
    "    for index,inputcol in enumerate(inputcols):\n",
    "        df[outputcols[index]] = df[inputcol].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "add_categorical_col(dtrain, inputcols,outputcols)\n",
    "add_categorical_col(dtest, inputcols,outputcols)\n",
    "print(dtrain.shape)\n",
    "print(dtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add ratio col:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 367)\n",
      "(1459, 366)\n"
     ]
    }
   ],
   "source": [
    "def add_col_ratio(df):\n",
    "    df['tota'] = df['LotArea'] + df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['1stFlrSF'] + df['2ndFlrSF'] + df['GrLivArea'] + df['GarageArea']\n",
    "    df['totfb'] = df['BsmtFullBath'] + df['FullBath']\n",
    "    df['tothb'] = df['BsmtHalfBath'] + df['HalfBath']\n",
    "    df['totbabgr'] = df['FullBath'] + df['HalfBath']\n",
    "    df['totb'] = df['BsmtFullBath'] + df['BsmtHalfBath'] + df['BedroomAbvGr']\n",
    "    \n",
    "    df['tota_totb'] = df['totb']/df['tota']\n",
    "    df['tota_totfb'] = df['totfb']/df['tota']\n",
    "    df['tota_tothb'] = df['tothb']/df['tota']\n",
    "    df['tota_br'] = df['BedroomAbvGr']/df['tota']\n",
    "    df['tota_kc'] = df['KitchenAbvGr']/df['tota']\n",
    "    df['tota_totrs'] = df['TotRmsAbvGrd']/df['tota']\n",
    "    df['tota_gc'] = df['GarageCars']/df['tota']\n",
    "    df['totbath_br'] = df['BedroomAbvGr']/(df['totbabgr']+1)\n",
    "    df['totfb_br'] = df['totfb']/(df['BedroomAbvGr']+1)\n",
    "    df['tothb_br'] = df['totfb']/(df['BedroomAbvGr']+1)\n",
    "    df['totb_totrm'] = df['TotRmsAbvGrd']/(df['totb']+1)\n",
    "    df['brm_kitchen'] = df['KitchenAbvGr']/(df['BedroomAbvGr']+1)\n",
    "    df['totrm_garacar'] = df['GarageCars']/(df['TotRmsAbvGrd']+1)\n",
    "    \n",
    "add_col_ratio(dtrain)\n",
    "add_col_ratio(dtest)\n",
    "print(dtrain.shape)\n",
    "print(dtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "net = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dtrain.drop('SalePrice', axis = 1)\n",
    "price = np.log(dtrain.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, price, test_size=0.2, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-10}\n",
      "0.8499838512639022\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'alpha': list(np.linspace(1e-10,100,10))}\n",
    " ]\n",
    "\n",
    "cv_lasso = GridSearchCV(lasso, param_grid, cv=10, n_jobs=-1)\n",
    "cv_lasso.fit(X_train, y_train)\n",
    "print(cv_lasso.best_params_)\n",
    "print(cv_lasso.best_score_)\n",
    "alpha_lasso = cv_lasso.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is R^2 0.931325!\n",
      "This is RMSE 0.009172!\n"
     ]
    }
   ],
   "source": [
    "cv_lasso.set_params()\n",
    "cv_lasso.fit(X_train, y_train)\n",
    "print('This is R^2 %f!' %cv_lasso.score(X_test, y_test))\n",
    "ypred = cv_lasso.predict(X_test)\n",
    "print('This is RMSE %f!' %sqrt(mean_squared_error(np.log(y_test), np.log(ypred))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dtrain.drop('SalePrice', axis = 1)\n",
    "price = np.log(dtrain.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, price, test_size=0.2, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 11.1111111112}\n",
      "0.9175733720077406\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'alpha': list(np.linspace(1e-10,100,10))}\n",
    " ]\n",
    "\n",
    "cv_ridge = GridSearchCV(ridge, param_grid, cv=10, n_jobs=-1)\n",
    "cv_ridge.fit(features,price)\n",
    "print(cv_ridge.best_params_)\n",
    "print(cv_ridge.best_score_)\n",
    "alpha_ridge = cv_ridge.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is R^2 0.941100!\n",
      "This is RMSE 0.008495!\n"
     ]
    }
   ],
   "source": [
    "cv_ridge.set_params()\n",
    "cv_ridge.fit(X_train, y_train)\n",
    "print('This is R^2 %f!' %cv_ridge.score(X_test, y_test))\n",
    "ypred = cv_ridge.predict(X_test)\n",
    "print('This is RMSE %f!' %sqrt(mean_squared_error(np.log(y_test), np.log(ypred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-10}\n",
      "0.8902090400984974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9535460125726289"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dtrain.drop('SalePrice', axis = 1)\n",
    "price = np.log(dtrain.SalePrice)\n",
    "\n",
    "param_grid = [\n",
    "  {'alpha': list(np.linspace(1e-10,100,10))}\n",
    " ]\n",
    "\n",
    "cv_lasso = GridSearchCV(lasso, param_grid, cv=10, n_jobs=-1)\n",
    "cv_lasso.fit(features,price)\n",
    "print(cv_lasso.best_params_)\n",
    "print(cv_lasso.best_score_)\n",
    "alpha_lasso = cv_lasso.best_params_['alpha']\n",
    "\n",
    "cv_lasso.set_params()\n",
    "cv_lasso.fit(features, price)\n",
    "cv_lasso.score(features, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 11.1111111112}\n",
      "0.9175733720077399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9427960227018534"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dtrain.drop('SalePrice', axis = 1)\n",
    "price = np.log(dtrain.SalePrice)\n",
    "\n",
    "param_grid = [\n",
    "  {'alpha': list(np.linspace(1e-10,100,10))}\n",
    " ]\n",
    "\n",
    "cv_ridge = GridSearchCV(ridge, param_grid, cv=10, n_jobs=-1)\n",
    "cv_ridge.fit(features,price)\n",
    "print(cv_ridge.best_params_)\n",
    "print(cv_ridge.best_score_)\n",
    "alpha_ridge = cv_ridge.best_params_['alpha']\n",
    "\n",
    "cv_ridge.set_params()\n",
    "cv_ridge.fit(features, price)\n",
    "cv_ridge.score(features, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-10, 'l1_ratio': 0.0}\n",
      "0.8912866218600334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9534804132295772"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dtrain.drop('SalePrice', axis = 1)\n",
    "price = np.log(dtrain.SalePrice)\n",
    "\n",
    "param_grid = [\n",
    "  {'alpha': list(np.linspace(1e-10,100,10)), 'l1_ratio': np.arange(0.0, 1.0, 0.1)}\n",
    " ]\n",
    "\n",
    "enet = ElasticNet()\n",
    "cv_enet = GridSearchCV(enet, param_grid, cv=10, n_jobs=-1)\n",
    "cv_enet.fit(features,price)\n",
    "print(cv_enet.best_params_)\n",
    "print(cv_enet.best_score_)\n",
    "\n",
    "cv_enet.set_params()\n",
    "cv_enet.fit(features, price)\n",
    "cv_enet.score(features, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([dtest.reset_index(), pd.Series(np.exp(cv_lasso.predict(dtest))).rename('SalePrice')], \\\n",
    "              axis=1)[['Id', 'SalePrice']].set_index('Id')\n",
    "x.to_csv('lasso_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([dtest.reset_index(), pd.Series(np.exp(cv_ridge.predict(dtest))).rename('SalePrice')], axis=1)[['Id', 'SalePrice']].set_index('Id')\n",
    "x.to_csv('ridge_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([dtest.reset_index(), pd.Series(np.exp(cv_enet.predict(dtest))).rename('SalePrice')], axis=1)[['Id', 'SalePrice']].set_index('Id')\n",
    "x.to_csv('enet_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
